{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convnet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seunghwan1228/Convolution_practice/blob/master/convnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjtJD_cvUqmY",
        "colab_type": "code",
        "outputId": "9d6b65a2-3503-48fa-83a9-7495ce09da1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras import layers, models\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbYPzcu_aBSx",
        "colab_type": "code",
        "outputId": "16bd2000-a0bd-476b-d19b-535ca2c193be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        }
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3,3), activation= 'relu', padding= 'same', input_shape = (150, 150, 3)))\n",
        "model.add(layers.MaxPool2D(2,2))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3,3), activation = 'relu', padding='same'))\n",
        "model.add(layers.MaxPool2D(2,2))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3,3), activation = 'relu', padding='same'))\n",
        "model.add(layers.MaxPool2D(2,2))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3,3), activation = 'relu', padding = 'same'))\n",
        "model.add(layers.MaxPool2D(2,2))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(512, activation = 'relu'))\n",
        "model.add(layers.Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0622 08:38:30.669476 140081594873728 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0622 08:38:30.711235 140081594873728 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0622 08:38:30.718327 140081594873728 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0622 08:38:30.745378 140081594873728 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 150, 150, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 75, 75, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 75, 75, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 37, 37, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 37, 37, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 18, 18, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 18, 18, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 9, 9, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10368)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               5308928   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 5,550,273\n",
            "Trainable params: 5,550,273\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzdPNlbYeTBT",
        "colab_type": "code",
        "outputId": "0d150e11-e470-4a84-adc8-4cce86c464c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0622 08:38:32.933264 140081594873728 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0622 08:38:32.965265 140081594873728 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0622 08:38:32.971554 140081594873728 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-3SRecgZ2rN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255, \n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2, \n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                  horizontal_flip=True,\n",
        "                                  vertical_flip = True)\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsj7tcGLbHGS",
        "colab_type": "code",
        "outputId": "2cbb3732-dba9-48d6-d096-2c8853f2faf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory('/content/drive/My Drive/input/Cats_vs_Dogs/4500', \n",
        "                                                    target_size = (150, 150), \n",
        "                                                   class_mode = 'binary',\n",
        "                                                   batch_size = 64)\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory('/content/drive/My Drive/input/Cats_vs_Dogs/cats vs dogs valid',\n",
        "                                                    target_size = (150, 150),\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    batch_size = 64)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9000 images belonging to 2 classes.\n",
            "Found 1002 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tpA5Dlu9Mv5",
        "colab_type": "code",
        "outputId": "2cd24c8b-6e1b-46b8-b93d-87e703871514",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "for data_batch, labels_batch in train_generator:\n",
        "    print('data batch shape:', data_batch.shape)\n",
        "    print('labels batch shape:', labels_batch.shape)\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data batch shape: (512, 150, 150, 3)\n",
            "labels batch shape: (512,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZChcHRKeSQ7",
        "colab_type": "code",
        "outputId": "127a6a94-0d37-41f7-83a8-ab9eab2779a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3617
        }
      },
      "source": [
        "history = model.fit_generator(train_generator, steps_per_epoch = 100, epochs = 100, validation_data=valid_generator, validation_steps=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 78s 777ms/step - loss: 0.5055 - acc: 0.7552 - val_loss: 0.4623 - val_acc: 0.7964\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 71s 705ms/step - loss: 0.5219 - acc: 0.7426 - val_loss: 0.4771 - val_acc: 0.7781\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 71s 713ms/step - loss: 0.5097 - acc: 0.7590 - val_loss: 0.4276 - val_acc: 0.7951\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 71s 712ms/step - loss: 0.4975 - acc: 0.7588 - val_loss: 0.4702 - val_acc: 0.7782\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 71s 711ms/step - loss: 0.4953 - acc: 0.7627 - val_loss: 0.4565 - val_acc: 0.8157\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 71s 708ms/step - loss: 0.4846 - acc: 0.7678 - val_loss: 0.4039 - val_acc: 0.8140\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 71s 707ms/step - loss: 0.4870 - acc: 0.7730 - val_loss: 0.4240 - val_acc: 0.8001\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 71s 714ms/step - loss: 0.4994 - acc: 0.7607 - val_loss: 0.4411 - val_acc: 0.8014\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 71s 711ms/step - loss: 0.4697 - acc: 0.7762 - val_loss: 0.4838 - val_acc: 0.7671\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 72s 717ms/step - loss: 0.4902 - acc: 0.7733 - val_loss: 0.4126 - val_acc: 0.8242\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 72s 720ms/step - loss: 0.4764 - acc: 0.7733 - val_loss: 0.3874 - val_acc: 0.8594\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 73s 727ms/step - loss: 0.4571 - acc: 0.7828 - val_loss: 0.4148 - val_acc: 0.8129\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 72s 716ms/step - loss: 0.4600 - acc: 0.7927 - val_loss: 0.3886 - val_acc: 0.8208\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 72s 720ms/step - loss: 0.4642 - acc: 0.7800 - val_loss: 0.3743 - val_acc: 0.8484\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 71s 713ms/step - loss: 0.4500 - acc: 0.7891 - val_loss: 0.4778 - val_acc: 0.7916\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 72s 718ms/step - loss: 0.4511 - acc: 0.7974 - val_loss: 0.3771 - val_acc: 0.8271\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 71s 714ms/step - loss: 0.4448 - acc: 0.7961 - val_loss: 0.4283 - val_acc: 0.8234\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 71s 714ms/step - loss: 0.4380 - acc: 0.8063 - val_loss: 0.3750 - val_acc: 0.8375\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 71s 713ms/step - loss: 0.4424 - acc: 0.8030 - val_loss: 0.3711 - val_acc: 0.8430\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 71s 714ms/step - loss: 0.4375 - acc: 0.8055 - val_loss: 0.3503 - val_acc: 0.8338\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 72s 719ms/step - loss: 0.4420 - acc: 0.8002 - val_loss: 0.5287 - val_acc: 0.7534\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 72s 718ms/step - loss: 0.4278 - acc: 0.8089 - val_loss: 0.3513 - val_acc: 0.8549\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 72s 715ms/step - loss: 0.4375 - acc: 0.8015 - val_loss: 0.4323 - val_acc: 0.7908\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 71s 713ms/step - loss: 0.4217 - acc: 0.8086 - val_loss: 0.3472 - val_acc: 0.8392\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 72s 716ms/step - loss: 0.4256 - acc: 0.8105 - val_loss: 0.5179 - val_acc: 0.7972\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 71s 707ms/step - loss: 0.4199 - acc: 0.8112 - val_loss: 0.3368 - val_acc: 0.8578\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 71s 711ms/step - loss: 0.4169 - acc: 0.8123 - val_loss: 0.3174 - val_acc: 0.8588\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 71s 712ms/step - loss: 0.4005 - acc: 0.8277 - val_loss: 0.4704 - val_acc: 0.7971\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 71s 711ms/step - loss: 0.4202 - acc: 0.8101 - val_loss: 0.3905 - val_acc: 0.8377\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 70s 704ms/step - loss: 0.4019 - acc: 0.8239 - val_loss: 0.4209 - val_acc: 0.8240\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 71s 712ms/step - loss: 0.4010 - acc: 0.8203 - val_loss: 0.3238 - val_acc: 0.8531\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 72s 718ms/step - loss: 0.4049 - acc: 0.8212 - val_loss: 0.3422 - val_acc: 0.8508\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 71s 715ms/step - loss: 0.4026 - acc: 0.8209 - val_loss: 0.3765 - val_acc: 0.8282\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 72s 716ms/step - loss: 0.3946 - acc: 0.8269 - val_loss: 0.3006 - val_acc: 0.8658\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 72s 715ms/step - loss: 0.3927 - acc: 0.8266 - val_loss: 0.7449 - val_acc: 0.8191\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 71s 714ms/step - loss: 0.3979 - acc: 0.8210 - val_loss: 0.4446 - val_acc: 0.8572\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 72s 716ms/step - loss: 0.3921 - acc: 0.8224 - val_loss: 0.3651 - val_acc: 0.8488\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 72s 717ms/step - loss: 0.3920 - acc: 0.8297 - val_loss: 0.3197 - val_acc: 0.8585\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 71s 710ms/step - loss: 0.3892 - acc: 0.8303 - val_loss: 0.3485 - val_acc: 0.8510\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 71s 709ms/step - loss: 0.3772 - acc: 0.8331 - val_loss: 0.4160 - val_acc: 0.8132\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - 71s 713ms/step - loss: 0.3873 - acc: 0.8321 - val_loss: 0.3134 - val_acc: 0.8687\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - 72s 718ms/step - loss: 0.3881 - acc: 0.8311 - val_loss: 0.2908 - val_acc: 0.8836\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - 72s 716ms/step - loss: 0.3761 - acc: 0.8372 - val_loss: 0.3570 - val_acc: 0.8547\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - 73s 728ms/step - loss: 0.3745 - acc: 0.8374 - val_loss: 0.2954 - val_acc: 0.8698\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - 73s 731ms/step - loss: 0.3779 - acc: 0.8311 - val_loss: 0.3188 - val_acc: 0.8641\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - 72s 716ms/step - loss: 0.3734 - acc: 0.8340 - val_loss: 0.3052 - val_acc: 0.8610\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - 71s 712ms/step - loss: 0.3805 - acc: 0.8328 - val_loss: 0.3155 - val_acc: 0.8599\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - 71s 708ms/step - loss: 0.3770 - acc: 0.8340 - val_loss: 0.3598 - val_acc: 0.8502\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - 71s 713ms/step - loss: 0.3737 - acc: 0.8344 - val_loss: 0.3067 - val_acc: 0.8810\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - 71s 706ms/step - loss: 0.3798 - acc: 0.8335 - val_loss: 0.3029 - val_acc: 0.8689\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - 71s 713ms/step - loss: 0.3736 - acc: 0.8403 - val_loss: 0.4889 - val_acc: 0.8526\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - 71s 710ms/step - loss: 0.3708 - acc: 0.8369 - val_loss: 0.3570 - val_acc: 0.8693\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - 71s 713ms/step - loss: 0.3696 - acc: 0.8408 - val_loss: 0.3053 - val_acc: 0.8862\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - 71s 715ms/step - loss: 0.3968 - acc: 0.8320 - val_loss: 0.2776 - val_acc: 0.8919\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - 71s 714ms/step - loss: 0.3570 - acc: 0.8473 - val_loss: 0.5607 - val_acc: 0.8334\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - 71s 710ms/step - loss: 0.3724 - acc: 0.8397 - val_loss: 0.3241 - val_acc: 0.8674\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - 71s 706ms/step - loss: 0.3730 - acc: 0.8383 - val_loss: 0.3254 - val_acc: 0.8665\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - 71s 708ms/step - loss: 0.3776 - acc: 0.8415 - val_loss: 0.3148 - val_acc: 0.8649\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - 71s 709ms/step - loss: 0.3673 - acc: 0.8380 - val_loss: 0.2867 - val_acc: 0.8941\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - 71s 712ms/step - loss: 0.3676 - acc: 0.8417 - val_loss: 0.3408 - val_acc: 0.8602\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - 71s 708ms/step - loss: 0.3504 - acc: 0.8471 - val_loss: 0.3561 - val_acc: 0.8732\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - 71s 706ms/step - loss: 0.3693 - acc: 0.8386 - val_loss: 0.3771 - val_acc: 0.8362\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - 72s 717ms/step - loss: 0.3760 - acc: 0.8413 - val_loss: 0.3265 - val_acc: 0.8797\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - 72s 723ms/step - loss: 0.3581 - acc: 0.8397 - val_loss: 0.2805 - val_acc: 0.8751\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - 72s 721ms/step - loss: 0.3648 - acc: 0.8367 - val_loss: 0.3332 - val_acc: 0.8504\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - 72s 724ms/step - loss: 0.3592 - acc: 0.8458 - val_loss: 0.3671 - val_acc: 0.8585\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - 72s 718ms/step - loss: 0.3573 - acc: 0.8479 - val_loss: 0.4172 - val_acc: 0.7837\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - 71s 710ms/step - loss: 0.3796 - acc: 0.8342 - val_loss: 0.3367 - val_acc: 0.8511\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - 71s 714ms/step - loss: 0.3586 - acc: 0.8439 - val_loss: 0.2853 - val_acc: 0.8845\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - 71s 706ms/step - loss: 0.3675 - acc: 0.8402 - val_loss: 0.2977 - val_acc: 0.8754\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - 71s 710ms/step - loss: 0.3466 - acc: 0.8441 - val_loss: 0.3186 - val_acc: 0.8872\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - 71s 709ms/step - loss: 0.3830 - acc: 0.8377 - val_loss: 0.3152 - val_acc: 0.8823\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - 71s 712ms/step - loss: 0.3558 - acc: 0.8402 - val_loss: 0.2685 - val_acc: 0.8826\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - 71s 712ms/step - loss: 0.3749 - acc: 0.8365 - val_loss: 0.4366 - val_acc: 0.8372\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - 72s 717ms/step - loss: 0.3620 - acc: 0.8396 - val_loss: 0.2807 - val_acc: 0.8918\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - 72s 717ms/step - loss: 0.3442 - acc: 0.8495 - val_loss: 0.3985 - val_acc: 0.8663\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - 72s 723ms/step - loss: 0.3616 - acc: 0.8434 - val_loss: 0.3382 - val_acc: 0.8746\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - 72s 716ms/step - loss: 0.3637 - acc: 0.8377 - val_loss: 0.3506 - val_acc: 0.8506\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - 71s 714ms/step - loss: 0.3653 - acc: 0.8424 - val_loss: 0.3743 - val_acc: 0.8609\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - 71s 710ms/step - loss: 0.3549 - acc: 0.8442 - val_loss: 0.3030 - val_acc: 0.8658\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - 71s 711ms/step - loss: 0.3662 - acc: 0.8379 - val_loss: 0.3487 - val_acc: 0.8374\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - 71s 708ms/step - loss: 0.3538 - acc: 0.8403 - val_loss: 0.3567 - val_acc: 0.8790\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - 71s 708ms/step - loss: 0.3529 - acc: 0.8464 - val_loss: 0.2903 - val_acc: 0.8872\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - 71s 710ms/step - loss: 0.3450 - acc: 0.8517 - val_loss: 2.8724 - val_acc: 0.6678\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - 71s 711ms/step - loss: 0.3873 - acc: 0.8310 - val_loss: 0.2667 - val_acc: 0.8907\n",
            "Epoch 86/100\n",
            "100/100 [==============================] - 71s 711ms/step - loss: 0.3698 - acc: 0.8398 - val_loss: 0.3029 - val_acc: 0.8726\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - 71s 713ms/step - loss: 0.3529 - acc: 0.8431 - val_loss: 0.6444 - val_acc: 0.7937\n",
            "Epoch 88/100\n",
            "100/100 [==============================] - 71s 711ms/step - loss: 0.3685 - acc: 0.8450 - val_loss: 0.3438 - val_acc: 0.8740\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - 71s 715ms/step - loss: 0.3791 - acc: 0.8314 - val_loss: 0.2684 - val_acc: 0.8813\n",
            "Epoch 90/100\n",
            "100/100 [==============================] - 72s 718ms/step - loss: 0.3504 - acc: 0.8453 - val_loss: 0.3065 - val_acc: 0.8578\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - 72s 719ms/step - loss: 0.3456 - acc: 0.8527 - val_loss: 0.3266 - val_acc: 0.8625\n",
            "Epoch 92/100\n",
            "100/100 [==============================] - 71s 713ms/step - loss: 0.3539 - acc: 0.8416 - val_loss: 0.3265 - val_acc: 0.8628\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - 71s 708ms/step - loss: 0.3761 - acc: 0.8456 - val_loss: 0.2917 - val_acc: 0.8665\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - 70s 705ms/step - loss: 0.3443 - acc: 0.8530 - val_loss: 0.3707 - val_acc: 0.8530\n",
            "Epoch 95/100\n",
            "100/100 [==============================] - 71s 710ms/step - loss: 0.3724 - acc: 0.8409 - val_loss: 0.3746 - val_acc: 0.8419\n",
            "Epoch 96/100\n",
            "100/100 [==============================] - 71s 709ms/step - loss: 0.3634 - acc: 0.8457 - val_loss: 0.5161 - val_acc: 0.8511\n",
            "Epoch 97/100\n",
            "100/100 [==============================] - 72s 717ms/step - loss: 0.3709 - acc: 0.8397 - val_loss: 0.2877 - val_acc: 0.8907\n",
            "Epoch 98/100\n",
            "100/100 [==============================] - 71s 711ms/step - loss: 0.3608 - acc: 0.8456 - val_loss: 0.2806 - val_acc: 0.8884\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - 71s 714ms/step - loss: 0.3811 - acc: 0.8399 - val_loss: 0.3187 - val_acc: 0.8617\n",
            "Epoch 100/100\n",
            "100/100 [==============================] - 72s 716ms/step - loss: 0.3609 - acc: 0.8470 - val_loss: 0.3019 - val_acc: 0.8631\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzNvjNw8hwhS",
        "colab_type": "code",
        "outputId": "8d1472ea-4687-4807-9020-2f0c198c2fb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 847
        }
      },
      "source": [
        "model2 = models.Sequential()\n",
        "model2.add(layers.Conv2D(32, (3,3), activation= 'relu', padding= 'same', input_shape = (150, 150, 3)))\n",
        "model2.add(layers.MaxPool2D(2,2))\n",
        "\n",
        "model2.add(layers.Conv2D(64, (3,3), activation = 'relu', padding='same'))\n",
        "model2.add(layers.MaxPool2D(2,2))\n",
        "\n",
        "model2.add(layers.Conv2D(128, (3,3), activation = 'relu', padding='same'))\n",
        "model2.add(layers.MaxPool2D(2,2))\n",
        "\n",
        "model2.add(layers.Conv2D(128, (3,3), activation = 'relu', padding = 'same'))\n",
        "model2.add(layers.MaxPool2D(2,2))\n",
        "\n",
        "model2.add(layers.Flatten())\n",
        "\n",
        "model2.add(layers.Dense(512, activation = 'relu'))\n",
        "model2.add(layers.Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model2.summary()\n",
        "\n",
        "model2.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0622 18:19:52.983578 140091894200192 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0622 18:19:53.029981 140091894200192 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0622 18:19:53.040852 140091894200192 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0622 18:19:53.069893 140091894200192 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0622 18:19:53.153724 140091894200192 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0622 18:19:53.173530 140091894200192 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0622 18:19:53.181275 140091894200192 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 150, 150, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 75, 75, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 75, 75, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 37, 37, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 37, 37, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 18, 18, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 18, 18, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 9, 9, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10368)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               5308928   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 5,550,273\n",
            "Trainable params: 5,550,273\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac7wOVhDiL2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmDmkakCiPKB",
        "colab_type": "code",
        "outputId": "d98ee713-e2b9-417a-96db-3da9f032cbf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory('/content/drive/input/Cats_vs_Dogs/4500', \n",
        "                                                    target_size = (150, 150), \n",
        "                                                   class_mode = 'binary',\n",
        "                                                   batch_size = 64)\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory('/content/drive/input/Cats_vs_Dogs/cats vs dogs valid',\n",
        "                                                    target_size = (150, 150),\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    batch_size = 64)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9000 images belonging to 2 classes.\n",
            "Found 1002 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d6nKG-liQ4a",
        "colab_type": "code",
        "outputId": "6e6fe5c4-0cc4-4fb5-c2d7-3297365a02af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3653
        }
      },
      "source": [
        "history2 = model2.fit_generator(train_generator, steps_per_epoch = 100, epochs = 100, validation_data=valid_generator, validation_steps=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0622 18:23:12.970412 140091894200192 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 2231s 22s/step - loss: 0.7989 - acc: 0.5337 - val_loss: 0.6907 - val_acc: 0.5166\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 821s 8s/step - loss: 0.6758 - acc: 0.6046 - val_loss: 0.5885 - val_acc: 0.6841\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 82s 819ms/step - loss: 0.6205 - acc: 0.6723 - val_loss: 0.5862 - val_acc: 0.7074\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 82s 817ms/step - loss: 0.5630 - acc: 0.7184 - val_loss: 0.4924 - val_acc: 0.7743\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 81s 807ms/step - loss: 0.5221 - acc: 0.7448 - val_loss: 0.4811 - val_acc: 0.7735\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 80s 798ms/step - loss: 0.4821 - acc: 0.7722 - val_loss: 0.4339 - val_acc: 0.7988\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 79s 794ms/step - loss: 0.4567 - acc: 0.7873 - val_loss: 0.4179 - val_acc: 0.8041\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 80s 804ms/step - loss: 0.4131 - acc: 0.8119 - val_loss: 0.4171 - val_acc: 0.8162\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 80s 797ms/step - loss: 0.3786 - acc: 0.8341 - val_loss: 0.4072 - val_acc: 0.7972\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 79s 791ms/step - loss: 0.3444 - acc: 0.8434 - val_loss: 0.3853 - val_acc: 0.8157\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 78s 780ms/step - loss: 0.3018 - acc: 0.8675 - val_loss: 0.4565 - val_acc: 0.8001\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 79s 790ms/step - loss: 0.2782 - acc: 0.8796 - val_loss: 0.3783 - val_acc: 0.8519\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 79s 790ms/step - loss: 0.2284 - acc: 0.9086 - val_loss: 0.5467 - val_acc: 0.7824\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 79s 787ms/step - loss: 0.1998 - acc: 0.9173 - val_loss: 0.4567 - val_acc: 0.8245\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 78s 775ms/step - loss: 0.1638 - acc: 0.9328 - val_loss: 0.5110 - val_acc: 0.8212\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 77s 771ms/step - loss: 0.1249 - acc: 0.9539 - val_loss: 0.5139 - val_acc: 0.8337\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 76s 764ms/step - loss: 0.1188 - acc: 0.9547 - val_loss: 0.5938 - val_acc: 0.8555\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 77s 770ms/step - loss: 0.0881 - acc: 0.9673 - val_loss: 0.5756 - val_acc: 0.8349\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 77s 770ms/step - loss: 0.0707 - acc: 0.9732 - val_loss: 0.6382 - val_acc: 0.8492\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 77s 773ms/step - loss: 0.0860 - acc: 0.9714 - val_loss: 0.5287 - val_acc: 0.8389\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 76s 762ms/step - loss: 0.0485 - acc: 0.9838 - val_loss: 0.8972 - val_acc: 0.8255\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 76s 760ms/step - loss: 0.0537 - acc: 0.9809 - val_loss: 0.6775 - val_acc: 0.8406\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 76s 764ms/step - loss: 0.0545 - acc: 0.9827 - val_loss: 0.8495 - val_acc: 0.8003\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 77s 774ms/step - loss: 0.0880 - acc: 0.9820 - val_loss: 0.7299 - val_acc: 0.8477\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 77s 769ms/step - loss: 0.0436 - acc: 0.9866 - val_loss: 0.7949 - val_acc: 0.8449\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 76s 762ms/step - loss: 0.0345 - acc: 0.9888 - val_loss: 0.8015 - val_acc: 0.8459\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 76s 761ms/step - loss: 0.0439 - acc: 0.9860 - val_loss: 0.6716 - val_acc: 0.8419\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 76s 765ms/step - loss: 0.0499 - acc: 0.9856 - val_loss: 0.7768 - val_acc: 0.8413\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 77s 765ms/step - loss: 0.0452 - acc: 0.9858 - val_loss: 0.9129 - val_acc: 0.8325\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 76s 764ms/step - loss: 0.0504 - acc: 0.9858 - val_loss: 1.2845 - val_acc: 0.8226\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 76s 762ms/step - loss: 0.0622 - acc: 0.9852 - val_loss: 0.9176 - val_acc: 0.8483\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 77s 766ms/step - loss: 0.0352 - acc: 0.9887 - val_loss: 1.0369 - val_acc: 0.8519\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 76s 762ms/step - loss: 0.0545 - acc: 0.9872 - val_loss: 0.9304 - val_acc: 0.8446\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 77s 765ms/step - loss: 0.0482 - acc: 0.9875 - val_loss: 1.0562 - val_acc: 0.8357\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 78s 780ms/step - loss: 0.0299 - acc: 0.9920 - val_loss: 1.1082 - val_acc: 0.8464\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 77s 773ms/step - loss: 0.0381 - acc: 0.9894 - val_loss: 1.0911 - val_acc: 0.8263\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 77s 771ms/step - loss: 0.0373 - acc: 0.9916 - val_loss: 0.9783 - val_acc: 0.8317\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 77s 769ms/step - loss: 0.0443 - acc: 0.9887 - val_loss: 1.1142 - val_acc: 0.8468\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 77s 770ms/step - loss: 0.0458 - acc: 0.9914 - val_loss: 1.2136 - val_acc: 0.8492\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 77s 774ms/step - loss: 0.0625 - acc: 0.9856 - val_loss: 1.1306 - val_acc: 0.8361\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - 77s 774ms/step - loss: 0.0388 - acc: 0.9919 - val_loss: 1.1552 - val_acc: 0.8500\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - 78s 776ms/step - loss: 0.0722 - acc: 0.9841 - val_loss: 1.0503 - val_acc: 0.8350\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - 76s 762ms/step - loss: 0.0375 - acc: 0.9919 - val_loss: 1.0662 - val_acc: 0.8362\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - 76s 762ms/step - loss: 0.0718 - acc: 0.9884 - val_loss: 1.1634 - val_acc: 0.8498\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - 77s 767ms/step - loss: 0.0567 - acc: 0.9883 - val_loss: 1.1249 - val_acc: 0.8393\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - 77s 770ms/step - loss: 0.0534 - acc: 0.9870 - val_loss: 1.1411 - val_acc: 0.8315\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - 78s 778ms/step - loss: 0.0417 - acc: 0.9897 - val_loss: 1.1145 - val_acc: 0.8073\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - 77s 775ms/step - loss: 0.0442 - acc: 0.9893 - val_loss: 0.9140 - val_acc: 0.8359\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - 77s 770ms/step - loss: 0.0487 - acc: 0.9922 - val_loss: 1.0421 - val_acc: 0.8003\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - 77s 766ms/step - loss: 0.0344 - acc: 0.9916 - val_loss: 1.4697 - val_acc: 0.8309\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - 77s 775ms/step - loss: 0.0588 - acc: 0.9869 - val_loss: 1.1468 - val_acc: 0.8438\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - 78s 775ms/step - loss: 0.0433 - acc: 0.9898 - val_loss: 1.3342 - val_acc: 0.8428\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - 77s 770ms/step - loss: 0.0410 - acc: 0.9906 - val_loss: 1.7813 - val_acc: 0.8145\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - 77s 768ms/step - loss: 0.0407 - acc: 0.9934 - val_loss: 1.2762 - val_acc: 0.8296\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - 76s 762ms/step - loss: 0.0374 - acc: 0.9909 - val_loss: 1.4769 - val_acc: 0.8369\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - 78s 776ms/step - loss: 0.0631 - acc: 0.9878 - val_loss: 1.2917 - val_acc: 0.8351\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - 76s 764ms/step - loss: 0.0516 - acc: 0.9886 - val_loss: 1.3854 - val_acc: 0.8496\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - 76s 764ms/step - loss: 0.0468 - acc: 0.9909 - val_loss: 1.4519 - val_acc: 0.8422\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - 76s 764ms/step - loss: 0.0508 - acc: 0.9887 - val_loss: 1.3261 - val_acc: 0.8438\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - 77s 767ms/step - loss: 0.0515 - acc: 0.9897 - val_loss: 1.3452 - val_acc: 0.8466\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - 76s 761ms/step - loss: 0.0480 - acc: 0.9915 - val_loss: 1.3986 - val_acc: 0.8331\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - 77s 768ms/step - loss: 0.0496 - acc: 0.9895 - val_loss: 1.3485 - val_acc: 0.8443\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - 77s 771ms/step - loss: 0.1183 - acc: 0.9831 - val_loss: 1.4367 - val_acc: 0.8310\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - 77s 766ms/step - loss: 0.0391 - acc: 0.9911 - val_loss: 1.2895 - val_acc: 0.8391\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - 76s 761ms/step - loss: 0.0706 - acc: 0.9879 - val_loss: 1.3782 - val_acc: 0.8369\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - 76s 759ms/step - loss: 0.0556 - acc: 0.9894 - val_loss: 1.4481 - val_acc: 0.8358\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - 77s 768ms/step - loss: 0.0405 - acc: 0.9902 - val_loss: 1.8768 - val_acc: 0.7883\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - 77s 768ms/step - loss: 0.0676 - acc: 0.9878 - val_loss: 1.3485 - val_acc: 0.8383\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - 77s 766ms/step - loss: 0.0422 - acc: 0.9916 - val_loss: 1.4734 - val_acc: 0.8223\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - 76s 762ms/step - loss: 0.0500 - acc: 0.9905 - val_loss: 0.9587 - val_acc: 0.8101\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - 76s 764ms/step - loss: 0.0486 - acc: 0.9908 - val_loss: 1.5071 - val_acc: 0.8288\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - 76s 763ms/step - loss: 0.0297 - acc: 0.9945 - val_loss: 1.6518 - val_acc: 0.8468\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - 77s 768ms/step - loss: 0.0645 - acc: 0.9891 - val_loss: 1.4246 - val_acc: 0.8349\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - 76s 763ms/step - loss: 0.0600 - acc: 0.9906 - val_loss: 1.7834 - val_acc: 0.8333\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - 77s 768ms/step - loss: 0.0788 - acc: 0.9887 - val_loss: 1.9400 - val_acc: 0.8189\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - 76s 765ms/step - loss: 0.0895 - acc: 0.9866 - val_loss: 1.4422 - val_acc: 0.8098\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - 76s 756ms/step - loss: 0.0394 - acc: 0.9930 - val_loss: 1.7795 - val_acc: 0.8417\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - 76s 765ms/step - loss: 0.0538 - acc: 0.9897 - val_loss: 1.4562 - val_acc: 0.8488\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - 77s 768ms/step - loss: 0.0559 - acc: 0.9898 - val_loss: 1.3332 - val_acc: 0.8296\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - 77s 768ms/step - loss: 0.0542 - acc: 0.9908 - val_loss: 1.7023 - val_acc: 0.8279\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - 76s 763ms/step - loss: 0.0440 - acc: 0.9912 - val_loss: 1.3890 - val_acc: 0.8307\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - 76s 764ms/step - loss: 0.0664 - acc: 0.9878 - val_loss: 1.4881 - val_acc: 0.8488\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - 76s 762ms/step - loss: 0.0501 - acc: 0.9900 - val_loss: 1.8276 - val_acc: 0.8376\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - 77s 772ms/step - loss: 0.0436 - acc: 0.9901 - val_loss: 1.7482 - val_acc: 0.8269\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - 77s 766ms/step - loss: 0.0389 - acc: 0.9922 - val_loss: 1.7893 - val_acc: 0.8184\n",
            "Epoch 86/100\n",
            "100/100 [==============================] - 77s 768ms/step - loss: 0.0467 - acc: 0.9911 - val_loss: 1.6319 - val_acc: 0.8298\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - 77s 768ms/step - loss: 0.0394 - acc: 0.9906 - val_loss: 1.7216 - val_acc: 0.8395\n",
            "Epoch 88/100\n",
            "100/100 [==============================] - 76s 763ms/step - loss: 0.0791 - acc: 0.9869 - val_loss: 1.7757 - val_acc: 0.8370\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - 77s 772ms/step - loss: 0.0732 - acc: 0.9885 - val_loss: 1.5845 - val_acc: 0.8373\n",
            "Epoch 90/100\n",
            "100/100 [==============================] - 77s 769ms/step - loss: 0.0679 - acc: 0.9908 - val_loss: 1.9188 - val_acc: 0.8280\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - 77s 769ms/step - loss: 0.0724 - acc: 0.9895 - val_loss: 2.1197 - val_acc: 0.8197\n",
            "Epoch 92/100\n",
            "100/100 [==============================] - 77s 765ms/step - loss: 0.0831 - acc: 0.9873 - val_loss: 1.5135 - val_acc: 0.8357\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - 77s 765ms/step - loss: 0.0591 - acc: 0.9931 - val_loss: 1.6026 - val_acc: 0.8537\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - 76s 762ms/step - loss: 0.0580 - acc: 0.9908 - val_loss: 1.5902 - val_acc: 0.8339\n",
            "Epoch 95/100\n",
            "100/100 [==============================] - 77s 768ms/step - loss: 0.0568 - acc: 0.9920 - val_loss: 2.0533 - val_acc: 0.8207\n",
            "Epoch 96/100\n",
            "100/100 [==============================] - 77s 769ms/step - loss: 0.0482 - acc: 0.9938 - val_loss: 1.7303 - val_acc: 0.8272\n",
            "Epoch 97/100\n",
            "100/100 [==============================] - 77s 773ms/step - loss: 0.0674 - acc: 0.9902 - val_loss: 1.7590 - val_acc: 0.8240\n",
            "Epoch 98/100\n",
            "100/100 [==============================] - 77s 766ms/step - loss: 0.0608 - acc: 0.9919 - val_loss: 1.6677 - val_acc: 0.8302\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - 76s 764ms/step - loss: 0.0434 - acc: 0.9923 - val_loss: 1.9157 - val_acc: 0.8481\n",
            "Epoch 100/100\n",
            "100/100 [==============================] - 76s 764ms/step - loss: 0.0567 - acc: 0.9911 - val_loss: 1.7447 - val_acc: 0.8420\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}